{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score,classification_report,roc_curve, ConfusionMatrixDisplay\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import random\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocessing:\n",
    "    def __init__(self,df):\n",
    "        self.raw_df = df.copy()\n",
    "\n",
    "    def check_null_values(self, col):\n",
    "        if df[col].isnull().sum() != 0:\n",
    "            # Drop na value\n",
    "            clean_df = self.raw_df.dropna(subset=col)\n",
    "            self.clean_df = clean_df\n",
    "            assert clean_df[col].isnull().sum() == 0\n",
    "        return clean_df\n",
    "    \n",
    "    def converted_label(self):\n",
    "        # Label converting to numeric ##\n",
    "        label_dict  = {\"WES\": 0,\n",
    "                \"panel\": 1}\n",
    "\n",
    "        self.clean_df[\"label\"]= self.clean_df[\"label\"].replace(label_dict)\n",
    "\n",
    "        assert self.clean_df[\"label\"].dtypes == \"int64\"\n",
    "\n",
    "        return self.clean_df\n",
    "    \n",
    "\n",
    "def split_pt(df, training_ratio):\n",
    "    mrn_unique = pd.DataFrame(df[\"EMPI\"].unique(), columns=[\"p_id\"])\n",
    "    p_id_train = mrn_unique.sample(n=int(len(mrn_unique)*training_ratio), replace=False) # 0.7 --> training ratio\n",
    "    p_id_test = mrn_unique.drop(index=p_id_train.index.values)\n",
    "\n",
    "    test_df = df.merge(p_id_test, right_on=\"p_id\", left_on=\"EMPI\")\n",
    "    train_df = df.merge(p_id_train, right_on=\"p_id\", left_on=\"EMPI\")\n",
    "    \n",
    "    tf_idf = TfidfVectorizer()\n",
    "    X_tf_idf_train = tf_idf.fit_transform(train_df[\"text\"])\n",
    "    X_tf_idf_test = tf_idf.transform(test_df[\"text\"])\n",
    "\n",
    "    return X_tf_idf_train, X_tf_idf_test, train_df, test_df\n",
    "\n",
    "\n",
    "def aggregate_by_mean(df,X_tf_idf):\n",
    "    aggregate_tfidf =  np.array([[]])\n",
    "    y = []\n",
    "    r = 0\n",
    "    for pt in df[\"EMPI\"].unique():\n",
    "        pt_tfidf = X_tf_idf[df[\"EMPI\"] == pt]\n",
    "        ## Aggregation: Mean\n",
    "        y.append(df[df[\"EMPI\"] == pt][\"label\"].unique()[0])\n",
    "        if r < 1:\n",
    "            aggregate_tfidf = np.array(pt_tfidf.mean(axis=0))\n",
    "        else:\n",
    "            aggregate_tfidf = np.concatenate((aggregate_tfidf, np.array(pt_tfidf.mean(axis=0))),axis=0)\n",
    "        r+=1\n",
    "    y = np.array(y)\n",
    "    return aggregate_tfidf, y\n",
    "\n",
    "\n",
    "def aggregate_main(X_tf_idf_train, X_tf_idf_test, train_df, test_df, method):\n",
    "    if method == \"mean\":\n",
    "        aggregate_tfidf_train, y_train = aggregate_by_mean(train_df, X_tf_idf_train)\n",
    "        aggregate_tfidf_test, y_test = aggregate_by_mean(test_df, X_tf_idf_test)\n",
    "    return  aggregate_tfidf_train, y_train, aggregate_tfidf_test, y_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26535/904894964.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.clean_df[\"label\"]= self.clean_df[\"label\"].replace(label_dict)\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "df = pd.read_csv(\"exported_data/df_withNotes.csv\")\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = preprocessing(df)\n",
    "clean_df = preprocessor.check_null_values(\"text\")\n",
    "clean_df = preprocessor.converted_label()\n",
    "clean_df.reset_index(drop=True,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tf_idf_train, X_tf_idf_test, train_df, test_df = split_pt(clean_df, 0.7)\n",
    "aggregate_tfidf_train, y_train, aggregate_tfidf_test, y_test = aggregate_main(X_tf_idf_train, X_tf_idf_test, train_df, test_df, \"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler(with_mean=False)),\n",
      "                ('pca', PCA(n_components=10)),\n",
      "                ('clf',\n",
      "                 RandomForestClassifier(max_depth=50, n_estimators=200))])\n",
      "{'clf__max_depth': 50, 'clf__n_estimators': 200, 'pca__n_components': 10}\n",
      "0.570446735395189\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         WES       0.56      0.90      0.69        70\n",
      "       panel       0.50      0.12      0.20        56\n",
      "\n",
      "    accuracy                           0.56       126\n",
      "   macro avg       0.53      0.51      0.45       126\n",
      "weighted avg       0.53      0.56      0.47       126\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.2, 'roc_panel': 0.5228316326530612, 'roc_wes': 0.47716836734693885}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_training(model, param_grid,X_train, y_train, X_test, y_test):\n",
    "    pipe = Pipeline([\n",
    "                      (\"scaler\", StandardScaler(with_mean=False)),\n",
    "                    (\"pca\",PCA()),\n",
    "                      (\"clf\", RandomForestClassifier())])\n",
    "    search = GridSearchCV(pipe, param_grid, n_jobs=4, cv=3)\n",
    "    search.fit(X_train, y_train)\n",
    "    print(search.best_estimator_)\n",
    "    print(search.best_params_)\n",
    "    print(search.best_score_)\n",
    "\n",
    "    ########### Predict ##################\n",
    "    y_pred = search.predict(X_test)\n",
    "    y_pred_prob = search.predict_proba(X_test)\n",
    "\n",
    "    ########### Evaluation ##################\n",
    "    performance_dict = {}\n",
    "    performance_dict[\"f1\"] = f1_score(y_test, y_pred)\n",
    "    performance_dict[\"roc_panel\"] = roc_auc_score(y_test, y_pred_prob[:,1])\n",
    "    print(classification_report(y_test, y_pred,target_names=[\"WES\",\"panel\"]))\n",
    "\n",
    "    ## Evluation metrics: roc, precision recall curve,  \n",
    "\n",
    "    return performance_dict\n",
    "\n",
    "param_grid = {\"pca__n_components\": [2, 10, 20],\n",
    "            \"clf__max_depth\":[10, 20, 30, 40, 50, None],\n",
    "              \"clf__n_estimators\": [100, 200,300]}\n",
    "\n",
    "model_training(RandomForestClassifier(),\n",
    "param_grid,aggregate_tfidf_train, y_train, aggregate_tfidf_test, y_test )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
