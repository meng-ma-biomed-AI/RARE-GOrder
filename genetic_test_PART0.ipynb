{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from new_utils import SolrManager\n",
    "from new_utils import OhdsiManager\n",
    "from new_utils import IdManager\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preliminary_analysis():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def get_info_raw(self):\n",
    "        '''Get the shape, number of unique patients, patient types, etc'''\n",
    "        print(f\"The shape of the data is {self.df.shape}\")\n",
    "\n",
    "        print(\"--------------------\")\n",
    "\n",
    "        print(f\"The number of patients in total: {self.df['Epic MRN'].nunique()}\")\n",
    "\n",
    "        print(\"--------------------\")\n",
    "        \n",
    "        print(self.df['label'].value_counts())\n",
    "        print(\"--------------------\")\n",
    "        print(self.df[\"Type of patient\"].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "class preprocessing():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def get_all_notes_from_MRN(self):\n",
    "        solr_note = SolrManager()\n",
    "        df_notes = pd.DataFrame()\n",
    "        df_exceptions_dict = {\"emp\": []}\n",
    "        MRN_list = self.df[\"Epic MRN\"].copy()\n",
    "        for i in tqdm_notebook(range(len(MRN_list))):\n",
    "            note = solr_note.get_note(MRN_list.iloc[i])\n",
    "            if note is None:\n",
    "                df_exceptions_dict[\"emp\"].append(MRN_list.iloc[i])\n",
    "                continue\n",
    "            # except KeyError:\n",
    "            #     df_exceptions_dict[\"emp\"].append(MRN_list.iloc[i])\n",
    "            #     continue\n",
    "            df_notes = pd.concat([df_notes, note],axis=0)\n",
    "\n",
    "        self.df = self.df.merge(df_notes,left_on=\"Epic MRN\", right_on=\"empi\")\n",
    "        self.df.drop(columns=[\"empi\"], inplace=True)\n",
    "        return self.df, df_exceptions_dict\n",
    "    \n",
    "    def maping_to_ids(self):\n",
    "        list_epic = list(df_whole[\"Epic MRN\"].copy())\n",
    "        id_mapping = IdManager(type='epic')\n",
    "        id_mapping.addIdList(list_epic)\n",
    "        id_mapping.getAllIds()\n",
    "        id_mapping.IdMappingDf[\"EMPI\"] = pd.to_numeric(id_mapping.IdMappingDf[\"EMPI\"])\n",
    "        print(\"Number of patients linked to EHR\")\n",
    "        print(id_mapping.IdMappingDf[\"person_id\"].nunique())\n",
    "        print(id_mapping.IdMappingDf.dtypes)\n",
    "        self.df = self.df.merge(id_mapping.IdMappingDf, left_on=\"Epic MRN\", right_on = \"EMPI\")\n",
    "        \n",
    "        return self.df\n",
    "\n",
    "class get_structure():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def get_demographics(self):\n",
    "        pid = tuple(set(self.df[\"person_id\"]))\n",
    "        where_clause = f\"WHERE p.person_id in {pid}\"\n",
    "        print(where_clause)\n",
    "        sql_query = f'''SELECT p.person_id, p.birth_datetime, \n",
    "                       p.ethnicity_source_value, p.gender_source_value, p.race_source_value\n",
    "                       FROM dbo.person p\n",
    "                       {where_clause}\n",
    "                       '''\n",
    "        connector = OhdsiManager()\n",
    "        demograhocs_df = connector.get_dataFromQuery(sql_query)\n",
    "        return demograhocs_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Notes & Select columns f\n",
    "df_WES = pd.read_excel(\"datasets/WES vs panel.xlsx\", \n",
    "                       sheet_name=\"WES-WGS\")\n",
    "df_panel = pd.read_excel(\"datasets/WES vs panel.xlsx\",\n",
    "                         sheet_name=\"Panel\")\n",
    "df_panel.rename(columns={\"Other features\":\"If other, specify:\"}, inplace=True)\n",
    "df_panel_WES = pd.read_excel(\"datasets/WES vs panel.xlsx\",\n",
    "                             sheet_name=\"Tiered-panel-WES\")\n",
    "\n",
    "df_panel_WES[\"label\"] = \"WES\"\n",
    "df_WES[\"label\"] = \"WES\"\n",
    "df_panel[\"label\"] = \"panel\"\n",
    "\n",
    "\n",
    "df_WES  = df_WES[[\"Epic MRN\", \"Primary indication\", \"If other, specify:\", \"Type of patient\", \"label\"]]\n",
    "df_panel = df_panel[[\"Epic MRN\",\"Primary indication\", \"If other, specify:\", \"Type of patient\",\"label\"]]\n",
    "df_panel_WES = df_panel_WES[[\"Epic MRN\", \"Primary indication\", \"If other, specify:\", \"Type of patient\", \"label\"]]\n",
    "\n",
    "df_whole = pd.concat([df_WES, df_panel, df_panel_WES], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "df_whole = df_whole.drop_duplicates()\n",
    "df_whole.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Remove invalid Epic MRN & Irrelevant\n",
    "# invalid_mrn list refer to data preprocessing.docx from the one-drive genetic testing project\n",
    "# invalid_mrn = [] \n",
    "drop_idx = []\n",
    "for mrn in invalid_mrn:\n",
    "    drop_idx.append(df_whole[df_whole[\"Epic MRN\"] == mrn].index.values[0])\n",
    "df_whole.drop(index=drop_idx, inplace=True)\n",
    "df_whole.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final df shape (1199, 5)\n",
      "The shape of the data is (1199, 5)\n",
      "--------------------\n",
      "The number of patients in total: 1199\n",
      "--------------------\n",
      "label\n",
      "WES      651\n",
      "panel    548\n",
      "Name: count, dtype: int64\n",
      "--------------------\n",
      "Type of patient\n",
      "Peds OP    919\n",
      "Peds IP    280\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final df shape {df_whole.shape}\")\n",
    "preliminary_analyzer = preliminary_analysis(df_whole)\n",
    "preliminary_analyzer.get_info_raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7113a20939e24b1f884a3bd8cf52e1cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Acquire all notes from chart\n",
    "preprocessor = preprocessing(df_whole)\n",
    "df_WithNotes, df_exceptions_dict = preprocessor.get_all_notes_from_MRN()\n",
    "# 417 unique patients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exceptions_d  = pd.DataFrame(df_exceptions_dict)\n",
    "df_exceptions_dict.to_csv(\"patients_Without_notes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics.to_csv(\"exported_data/pt_demographics.csv\", index=False)\n",
    "df_WithNotes.to_csv(\"exported_data/df_withNotes.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
